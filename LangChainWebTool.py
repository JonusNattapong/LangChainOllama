# Enhanced LangChain Agent + Web Tool (Search API)
# Install: pip install langchain langchain-community langchain-ollama duckduckgo-search

from langchain_community.tools import DuckDuckGoSearchRun
from langchain.agents import initialize_agent, Tool, AgentType
from langchain_ollama import OllamaLLM
from langchain.memory import ConversationBufferMemory
import logging
from typing import Optional, Dict, Any

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class WebSearchAgent:
    def __init__(self, model_name: str = "qwen3:1.7b", max_iterations: int = 3):
        """Initialize the web search agent with configurable parameters."""
        self.model_name = model_name
        self.max_iterations = max_iterations
        self.llm = None
        self.agent = None
        self.memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
        self._setup_agent()
    
    def search_with_fallback(self, query: str) -> str:
        """Enhanced search function with multiple fallback strategies."""
        if not isinstance(query, str) or not query.strip():
            return "Final Answer: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
        
        # Strategy 1: Try API backend first
        try:
            logger.info(f"Searching with API backend: {query}")
            search_tool = DuckDuckGoSearchRun(backend="api", max_results=5)
            result = search_tool.run(query.strip())
            if result and len(result.strip()) > 10:  # Basic quality check
                return f"Final Answer: {result}"
        except Exception as e:
            logger.warning(f"API backend failed: {str(e)}")
        
        # Strategy 2: Try HTML backend
        try:
            logger.info(f"Fallback to HTML backend: {query}")
            search_tool = DuckDuckGoSearchRun(backend="html", max_results=3)
            result = search_tool.run(query.strip())
            if result and len(result.strip()) > 10:
                return f"Final Answer: {result}"
        except Exception as e:
            logger.warning(f"HTML backend failed: {str(e)}")
        
        # Strategy 3: Try with simplified query
        try:
            simplified_query = query.replace("‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î", "").replace("‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ", "").strip()
            if simplified_query and simplified_query != query:
                logger.info(f"Trying simplified query: {simplified_query}")
                search_tool = DuckDuckGoSearchRun(backend="api", max_results=3)
                result = search_tool.run(simplified_query)
                if result and len(result.strip()) > 10:
                    return f"Final Answer: {result}"
        except Exception as e:
            logger.warning(f"Simplified query failed: {str(e)}")
        
        return "Final Answer: ‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤"
    
    def _setup_agent(self):
        """Setup the LLM and agent with tools."""
        try:
            # Initialize LLM
            self.llm = OllamaLLM(
                model=self.model_name,
                temperature=0.1,  # Lower temperature for more focused responses
                num_predict=1000,  # Limit response length
            )
            
            # Create enhanced search tool
            search_tool = Tool(
                name="web_search",
                func=self.search_with_fallback,
                description="""Use this tool to search for current information from the internet using DuckDuckGo.
                Best for: latest news, current events, recent technology updates, real-time information.
                Input should be a clear, specific search query in Thai or English.
                The tool automatically returns 'Final Answer:' so don't add it yourself."""
            )
            
            # Initialize agent with memory
            self.agent = initialize_agent(
                tools=[search_tool],
                llm=self.llm,
                agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                verbose=True,
                max_iterations=self.max_iterations,
                handle_parsing_errors=True,
                memory=self.memory,
                agent_kwargs={
                    "prefix": """You are a helpful AI assistant that can search the web for current information.
                    When asked about recent events, news, or current information, use the web_search tool.
                    Always provide responses in Thai when the user asks in Thai.
                    Be concise but informative in your responses."""
                }
            )
            logger.info("Agent initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to setup agent: {str(e)}")
            raise
    
    def query(self, question: str) -> Dict[str, Any]:
        """Process a query and return structured response."""
        try:
            logger.info(f"Processing query: {question}")
            response = self.agent.invoke({"input": question})
            
            return {
                "success": True,
                "output": response.get("output", str(response)),
                "chat_history": self.memory.chat_memory.messages if hasattr(self.memory, 'chat_memory') else []
            }
            
        except Exception as e:
            logger.error(f"Query processing failed: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "output": f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
            }
    
    def clear_memory(self):
        """Clear conversation memory."""
        self.memory.clear()
        logger.info("Memory cleared")

# Convenience function for quick usage
def create_search_agent(model: str = "llama3.2:3b") -> WebSearchAgent:
    """Create and return a configured web search agent."""
    return WebSearchAgent(model_name=model)

# Example usage and testing
if __name__ == "__main__":
    # Initialize agent
    agent = create_search_agent()
    
    # Test queries
    test_queries = [
        "‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ AI ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ",
        "What are the latest developments in renewable energy?",
        "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ",
        "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÅ‡∏•‡∏Å‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏á‡∏¥‡∏ô‡∏ö‡∏≤‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"
    ]
    
    print("ü§ñ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö LangChain Web Search Agent\n")
    print("=" * 60)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\nüìã ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ó‡∏µ‡πà {i}: {query}")
        print("-" * 40)
        
        result = agent.query(query)
        
        if result["success"]:
            print(f"‚úÖ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {result['output']}")
        else:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {result['error']}")
        
        print("-" * 40)
    
    print(f"\nüéâ ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
    
    # Interactive mode
    print(f"\nüí¨ ‡πÇ‡∏´‡∏°‡∏î‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö (‡∏û‡∏¥‡∏°‡∏û‡πå 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å)")
    while True:
        try:
            user_input = input("\nüôã ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ").strip()
            if user_input.lower() in ['quit', 'exit', '‡∏≠‡∏≠‡∏Å']:
                break
            
            if user_input:
                result = agent.query(user_input)
                print(f"\nü§ñ ‡∏ï‡∏≠‡∏ö: {result['output']}")
            else:
                print("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
                
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
    
    print("\nüëã ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")